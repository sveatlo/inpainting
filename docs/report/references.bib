@article{yu2018free,
	title={Free-Form Image Inpainting with Gated Convolution},
	author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
	journal={arXiv preprint arXiv:1806.03589},
	year={2018}
}

@inproceedings{quilting,
	author = {Efros, Alexei A. and Freeman, William T.},
	title = {Image Quilting for Texture Synthesis and Transfer},
	year = {2001},
	isbn = {158113374X},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/383259.383296},
	abstract = {We present a simple image-based method of generating novel visual appearance in which a new image is synthesized by stitching together small patches of existing images. We call this process image quilting. First, we use quilting as a fast and very simple texture synthesis algorithm which produces surprisingly good results for a wide range of textures. Second, we extend the algorithm to perform texture transfer — rendering an object with a texture taken from a different object. More generally, we demonstrate how an image can be re-rendered in the style of a different image. The method works directly on the images and does not require 3D information.},
	booktitle = {Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques},
	pages = {341–346},
	numpages = {6},
	keywords = {texture mapping, texture synthesis, image-based rendering},
	series = {SIGGRAPH '01}
}

@inproceedings{Efros99,
    AUTHOR  = {Alexei A. Efros and Thomas K. Leung},
    TITLE   = {Texture Synthesis by Non-parametric Sampling},
    BOOKTITLE = {IEEE International Conference on Computer Vision},
    YEAR    = {1999},
    ADDRESS = {Corfu, Greece},
    MONTH   = {September},
    PAGES   = {1033-1038}
}

@misc{li2017generative,
      title={Generative Face Completion}, 
      author={Yijun Li and Sifei Liu and Jimei Yang and Ming-Hsuan Yang},
      year={2017},
      eprint={1704.05838},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yeh2017semantic,
      title={Semantic Image Inpainting with Deep Generative Models}, 
      author={Raymond A. Yeh and Chen Chen and Teck Yian Lim and Alexander G. Schwing and Mark Hasegawa-Johnson and Minh N. Do},
      year={2017},
      eprint={1607.07539},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{pathak2016context,
      title={Context Encoders: Feature Learning by Inpainting}, 
      author={Deepak Pathak and Philipp Krahenbuhl and Jeff Donahue and Trevor Darrell and Alexei A. Efros},
      year={2016},
      eprint={1604.07379},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{globloc,
	author = {Iizuka, Satoshi and Simo-Serra, Edgar and Ishikawa, Hiroshi},
	title = {Globally and Locally Consistent Image Completion},
	year = {2017},
	issue_date = {July 2017},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {36},
	number = {4},
	issn = {0730-0301},
	doi = {10.1145/3072959.3073659},
	abstract = {We present a novel approach for image completion that results in images that are both locally and globally consistent. With a fully-convolutional neural network, we can complete images of arbitrary resolutions by filling-in missing regions of any shape. To train this image completion network to be consistent, we use global and local context discriminators that are trained to distinguish real images from completed ones. The global discriminator looks at the entire image to assess if it is coherent as a whole, while the local discriminator looks only at a small area centered at the completed region to ensure the local consistency of the generated patches. The image completion network is then trained to fool the both context discriminator networks, which requires it to generate images that are indistinguishable from real ones with regard to overall consistency as well as in details. We show that our approach can be used to complete a wide variety of scenes. Furthermore, in contrast with the patch-based approaches such as PatchMatch, our approach can generate fragments that do not appear elsewhere in the image, which allows us to naturally complete the images of objects with familiar and highly specific structures, such as faces.},
	journal = {ACM Trans. Graph.},
	month = jul,
	articleno = {107},
	numpages = {14},
	keywords = {image completion, convolutional neural network}
}

@misc{yu2018generative,
      title={Generative Image Inpainting with Contextual Attention}, 
      author={Jiahui Yu and Zhe Lin and Jimei Yang and Xiaohui Shen and Xin Lu and Thomas S. Huang},
      year={2018},
      eprint={1801.07892},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{liu2018image,
	title={Image inpainting for irregular holes using partial convolutions},
	author={Liu, Guilin and Reda, Fitsum A and Shih, Kevin J and Wang, Ting-Chun and Tao, Andrew and Catanzaro, Bryan},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={85--100},
	year={2018}
}

@inproceedings{liu2015faceattributes,
	title = {Deep Learning Face Attributes in the Wild},
	author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
	booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
	month = {December},
	year = {2015} 
}

@misc{anwar2020masked,
	title={Masked Face Recognition for Secure Authentication},
	author={Aqeel Anwar and Arijit Raychowdhury},
	year={2020},
	eprint={2008.11104},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
} 

@misc{kingma2017adam,
	title={Adam: A Method for Stochastic Optimization}, 
	author={Diederik P. Kingma and Jimmy Ba},
	year={2017},
	eprint={1412.6980},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}